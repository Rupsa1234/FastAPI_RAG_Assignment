
Overview:

This project showcases an implementation of Generative AI techniques using state-of-the-art models and libraries. The aim is to explore and apply generative methods in various domains, focusing on practical use cases and efficiency. 
The project includes the creation of a lightweight FastAPI server designed for Retrieval-Augmented Generation (RAG), integrating ChromaDB for vector storage and the Hugging Face's Sentence-Transformers model for generating meaningful responses from large datasets.

Features:

- FastAPI Server: A REST API server built with FastAPI that enables seamless integration with external services and platforms.
- ChromaDB: Efficient storage and retrieval of vectorized data using ChromaDB, allowing for quick and relevant data searches.
- Hugging Face Sentence-Transformers: Utilized for generating embeddings and powering the RAG pipeline for effective retrieval and response generation.
- End-to-End Pipeline: The project demonstrates an end-to-end solution from model deployment to real-time generation of responses, focusing on scalability and performance.

Requirements:

Python 3.8+

FastAPI: Web framework for building the server.

ChromaDB: Vector database for storing and querying embeddings.

Sentence-Transformers: For generating embeddings and performing retrieval-augmented generation.

Uvicorn: ASGI server for FastAPI.

Pip: For managing dependencies.
